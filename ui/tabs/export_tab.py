"""
Onglet d'exportation des r√©sultats
"""

import streamlit as st
import pandas as pd
import io
import json
from datetime import datetime
from utils.data_manager import get_test_results, is_test_completed
from utils.helpers import create_benchmark_summary, export_results_to_json, format_test_results_summary

# Import conditionnel pour la visualisation
try:
    from visualization.visualizer import ResultVisualizer
    VISUALIZER_AVAILABLE = True
except ImportError:
    VISUALIZER_AVAILABLE = False

def render_export_tab():
    """Affiche l'onglet d'exportation"""
    st.header("üì§ Exportation des r√©sultats")
    
    if not is_test_completed():
        st.info("‚ÑπÔ∏è Aucun test n'a encore √©t√© ex√©cut√©. Allez dans l'onglet 'Configuration et tests' pour lancer les tests.")
        
        # Afficher un guide d'utilisation
        with st.expander("üìñ Guide pour commencer"):
            st.markdown("""
            ### Comment effectuer vos premiers tests
            
            1. **Aller dans l'onglet 'Configuration et tests'**
            2. **Configurer les endpoints** dans la barre lat√©rale (ou utiliser les endpoints de test)
            3. **S√©lectionner les types de requ√™tes** √† tester
            4. **Cliquer sur 'Ex√©cuter les tests'**
            5. **Revenir ici** pour exporter les r√©sultats
            
            ### Endpoints de test recommand√©s
            
            Si vous n'avez pas encore configur√© vos moteurs SPARQL locaux, vous pouvez utiliser :
            - **DBpedia public** : `https://dbpedia.org/sparql`
            - **Wikidata public** : `https://query.wikidata.org/sparql`
            
            ‚ö†Ô∏è *Note: Les endpoints publics peuvent √™tre plus lents et avoir des limitations*
            """)
        
        return
    
    results_df = get_test_results()
    
    if results_df is None or results_df.empty:
        st.warning("‚ö†Ô∏è Aucun r√©sultat disponible pour l'exportation.")
        st.info("Les tests semblent avoir √©t√© ex√©cut√©s mais aucune donn√©e n'a √©t√© sauvegard√©e.")
        return
    
    # V√©rifier la validit√© des donn√©es
    if not _validate_results_data(results_df):
        st.error("‚ùå Les donn√©es de r√©sultats sont incompl√®tes ou corrompues.")
        st.info("Veuillez relancer les tests pour obtenir des donn√©es valides.")
        return
    
    # Section d'exportation des donn√©es brutes
    render_data_export_section(results_df)
    
    # Section de g√©n√©ration de rapports
    render_report_generation_section(results_df)
    
    # Section d'exportation de visualisations
    render_visualization_export_section(results_df)

def _validate_results_data(results_df: pd.DataFrame) -> bool:
    """
    Valide que les donn√©es de r√©sultats contiennent les colonnes n√©cessaires
    
    Args:
        results_df: DataFrame des r√©sultats
        
    Returns:
        True si les donn√©es sont valides
    """
    required_columns = ['execution_time', 'success', 'engine']
    missing_columns = [col for col in required_columns if col not in results_df.columns]
    
    if missing_columns:
        st.warning(f"‚ö†Ô∏è Colonnes manquantes dans les donn√©es: {', '.join(missing_columns)}")
        st.write("**Colonnes disponibles:**", list(results_df.columns))
        return False
    
    return True

def render_data_export_section(results_df: pd.DataFrame):
    """
    Affiche la section d'exportation des donn√©es brutes
    
    Args:
        results_df: DataFrame des r√©sultats
    """
    st.subheader("üìä Exportation des donn√©es brutes")
    
    # Aper√ßu des donn√©es
    with st.expander("üëÄ Aper√ßu des donn√©es √† exporter"):
        st.write(f"**Nombre total d'enregistrements:** {len(results_df)}")
        st.write(f"**Colonnes disponibles:** {', '.join(results_df.columns)}")
        st.dataframe(results_df.head(10), use_container_width=True)
    
    # Options d'exportation
    col1, col2 = st.columns(2)
    
    with col1:
        export_format = st.radio(
            "üìÅ Format d'exportation",
            options=["CSV", "Excel", "JSON"],
            help="Choisissez le format pour exporter les donn√©es"
        )
    
    with col2:
        include_metadata = st.checkbox(
            "Inclure les m√©tadonn√©es",
            value=True,
            help="Ajouter des informations sur l'export (date, configuration, etc.)"
        )
    
    # G√©n√©ration et t√©l√©chargement
    try:
        if export_format == "CSV":
            render_csv_export(results_df, include_metadata)
        elif export_format == "Excel":
            render_excel_export(results_df, include_metadata)
        elif export_format == "JSON":
            render_json_export(results_df, include_metadata)
    except Exception as e:
        st.error(f"Erreur lors de l'export {export_format}: {str(e)}")

def render_csv_export(results_df: pd.DataFrame, include_metadata: bool):
    """
    G√®re l'export CSV
    
    Args:
        results_df: DataFrame des r√©sultats
        include_metadata: Inclure les m√©tadonn√©es
    """
    try:
        csv_data = results_df.to_csv(index=False)
        
        if include_metadata:
            metadata = f"""# R√©sultats de performance SPARQL
# G√©n√©r√© le: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# Nombre d'enregistrements: {len(results_df)}
# Colonnes: {', '.join(results_df.columns)}

"""
            csv_data = metadata + csv_data
        
        st.download_button(
            label="üì• T√©l√©charger en CSV",
            data=csv_data,
            file_name=f"sparql_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            help="T√©l√©charge les r√©sultats au format CSV"
        )
        
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du CSV: {str(e)}")

def render_excel_export(results_df: pd.DataFrame, include_metadata: bool):
    """
    G√®re l'export Excel
    
    Args:
        results_df: DataFrame des r√©sultats
        include_metadata: Inclure les m√©tadonn√©es
    """
    try:
        buffer = io.BytesIO()
        
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            # Feuille principale avec les r√©sultats
            results_df.to_excel(writer, sheet_name='R√©sultats', index=False)
            
            # Feuille r√©sum√© si le visualiseur est disponible
            if VISUALIZER_AVAILABLE and _validate_results_data(results_df):
                try:
                    from visualization.visualizer import ResultVisualizer
                    visualizer = ResultVisualizer()
                    summary_table = visualizer.create_summary_table(results_df)
                    summary_table.to_excel(writer, sheet_name='R√©sum√©', index=False)
                except Exception:
                    pass  # Ignorer si le r√©sum√© ne peut pas √™tre cr√©√©
            
            # Feuille statistiques
            if 'execution_time' in results_df.columns and 'query_name' in results_df.columns and 'engine' in results_df.columns:
                try:
                    stats_df = results_df.groupby(['query_name', 'engine']).agg({
                        'execution_time': ['mean', 'min', 'max', 'std', 'count'],
                        'success': 'mean'
                    }).round(4)
                    stats_df.to_excel(writer, sheet_name='Statistiques')
                except Exception:
                    pass  # Ignorer si les statistiques ne peuvent pas √™tre cr√©√©es
            
            # M√©tadonn√©es si demand√©es
            if include_metadata:
                metadata_df = pd.DataFrame({
                    'Param√®tre': [
                        'Date de g√©n√©ration',
                        'Nombre d\'enregistrements',
                        'Nombre de requ√™tes uniques',
                        'Nombre de moteurs test√©s',
                        'Taux de succ√®s global (%)'
                    ],
                    'Valeur': [
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        len(results_df),
                        results_df['query_name'].nunique() if 'query_name' in results_df.columns else 'N/A',
                        results_df['engine'].nunique() if 'engine' in results_df.columns else 'N/A',
                        f"{results_df['success'].mean() * 100:.2f}" if 'success' in results_df.columns else 'N/A'
                    ]
                })
                metadata_df.to_excel(writer, sheet_name='M√©tadonn√©es', index=False)
        
        buffer.seek(0)
        
        st.download_button(
            label="üì• T√©l√©charger en Excel",
            data=buffer,
            file_name=f"sparql_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="T√©l√©charge les r√©sultats au format Excel avec feuilles multiples"
        )
        
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du fichier Excel: {str(e)}")

def render_json_export(results_df: pd.DataFrame, include_metadata: bool):
    """
    G√®re l'export JSON
    
    Args:
        results_df: DataFrame des r√©sultats
        include_metadata: Inclure les m√©tadonn√©es
    """
    try:
        json_data = export_results_to_json(results_df)
        
        st.download_button(
            label="üì• T√©l√©charger en JSON",
            data=json_data,
            file_name=f"sparql_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            help="T√©l√©charge les r√©sultats au format JSON avec m√©tadonn√©es"
        )
        
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du JSON: {str(e)}")

def render_report_generation_section(results_df: pd.DataFrame):
    """
    Affiche la section de g√©n√©ration de rapports
    
    Args:
        results_df: DataFrame des r√©sultats
    """
    st.subheader("üìù G√©n√©ration de rapports")
    
    # V√©rifier si les donn√©es sont suffisantes pour un rapport
    if not _validate_results_data(results_df):
        st.warning("‚ö†Ô∏è Donn√©es insuffisantes pour g√©n√©rer un rapport complet.")
        return
    
    report_type = st.selectbox(
        "üìã Type de rapport",
        options=[
            "Rapport complet",
            "R√©sum√© ex√©cutif",
            "Rapport technique",
            "Comparaison des moteurs",
            "Analyse de performance"
        ],
        help="Choisissez le type de rapport √† g√©n√©rer"
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        include_charts_desc = st.checkbox(
            "Inclure les descriptions de graphiques",
            value=True,
            help="Ajouter des descriptions d√©taill√©es des visualisations"
        )
    
    with col2:
        include_recommendations = st.checkbox(
            "Inclure les recommandations",
            value=True,
            help="Ajouter des recommandations bas√©es sur l'analyse"
        )
    
    if st.button("üìÑ G√©n√©rer le rapport", type="primary"):
        with st.spinner("G√©n√©ration du rapport en cours..."):
            try:
                report_content = generate_report_safe(
                    results_df, 
                    report_type, 
                    include_charts_desc, 
                    include_recommendations
                )
                
                # Aper√ßu du rapport
                st.subheader("üëÄ Aper√ßu du rapport")
                with st.expander("Voir le contenu du rapport", expanded=True):
                    st.markdown(report_content)
                
                # T√©l√©chargement du rapport
                st.download_button(
                    label="üì• T√©l√©charger le rapport",
                    data=report_content,
                    file_name=f"rapport_sparql_{report_type.lower().replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown",
                    help="T√©l√©charge le rapport au format Markdown"
                )
                
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration du rapport: {str(e)}")
                st.info("V√©rifiez que les donn√©es de test sont compl√®tes et valides.")
                
                # Rapport d'erreur d√©taill√©
                error_report = f"""# Erreur lors de la g√©n√©ration du rapport

**Erreur rencontr√©e:** {str(e)}

**Informations de d√©bogage:**
- Nombre d'enregistrements: {len(results_df)}
- Colonnes disponibles: {', '.join(results_df.columns)}
- Types de donn√©es: {dict(results_df.dtypes)}

**Suggestions:**
1. V√©rifiez que les tests ont √©t√© ex√©cut√©s correctement
2. Assurez-vous que les colonnes requises sont pr√©sentes
3. Contactez le support technique si le probl√®me persiste

---
*Rapport d'erreur g√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
                
                st.download_button(
                    label="üì• T√©l√©charger le rapport d'erreur",
                    data=error_report,
                    file_name=f"erreur_rapport_sparql_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown",
                    help="T√©l√©charge un rapport d'erreur pour diagnostic"
                )

def generate_report_safe(results_df: pd.DataFrame, report_type: str, 
                        include_charts: bool, include_recommendations: bool) -> str:
    """
    G√©n√®re un rapport de mani√®re s√©curis√©e avec gestion d'erreurs
    
    Args:
        results_df: DataFrame des r√©sultats
        report_type: Type de rapport √† g√©n√©rer
        include_charts: Inclure les descriptions de graphiques
        include_recommendations: Inclure les recommandations
        
    Returns:
        Contenu du rapport en Markdown
    """
    try:
        # En-t√™te du rapport
        report = f"""# {report_type} - Performance SPARQL

**Date de g√©n√©ration:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## R√©sum√© ex√©cutif

"""
        
        # Informations de base sur les donn√©es
        report += f"""
### Donn√©es analys√©es

- **Nombre d'enregistrements:** {len(results_df)}
- **Colonnes disponibles:** {', '.join(results_df.columns)}
- **P√©riode d'analyse:** {datetime.now().strftime('%Y-%m-%d')}

"""
        
        # Tentative de g√©n√©ration du r√©sum√© avec gestion d'erreur
        try:
            summary = create_benchmark_summary(results_df)
            
            # V√©rifier si le r√©sum√© contient une erreur
            if "error" in summary:
                report += f"""
### ‚ö†Ô∏è Limitation de l'analyse

Les m√©triques avanc√©es ne peuvent pas √™tre calcul√©es : {summary['error']}

**Analyse basique disponible:**
- Nombre total d'enregistrements: {len(results_df)}
- Colonnes pr√©sentes: {', '.join(results_df.columns)}

"""
            else:
                # R√©sum√© complet disponible
                report += f"""
### Aper√ßu g√©n√©ral

- **Nombre total d'ex√©cutions:** {summary['overview']['total_executions']}
- **Requ√™tes uniques test√©es:** {summary['overview']['unique_queries']}
- **Moteurs √©valu√©s:** {summary['overview']['engines_tested']}
- **Taux de succ√®s global:** {summary['overview']['success_rate']:.2f}%

### Performance globale

- **Temps d'ex√©cution moyen:** {summary['performance']['avg_execution_time']:.4f} secondes
- **Temps minimum observ√©:** {summary['performance']['min_execution_time']:.4f} secondes
- **Temps maximum observ√©:** {summary['performance']['max_execution_time']:.4f} secondes
- **√âcart-type:** {summary['performance']['std_execution_time']:.4f} secondes

### Utilisation des ressources

- **CPU moyen:** {summary['resources']['avg_cpu_usage']:.2f}%
- **M√©moire moyenne:** {summary['resources']['avg_memory_usage']:.2f} MB
- **CPU maximum:** {summary['resources']['max_cpu_usage']:.2f}%
- **M√©moire maximum:** {summary['resources']['max_memory_usage']:.2f} MB

"""
        except Exception as e:
            # Fallback si le r√©sum√© √©choue
            report += f"""
### ‚ö†Ô∏è Analyse limit√©e

Impossible de g√©n√©rer un r√©sum√© complet des performances.

**Raison:** {str(e)}

**Donn√©es brutes disponibles:**
- {len(results_df)} enregistrements au total
- Colonnes: {', '.join(results_df.columns)}

"""
        
        # Ajouter une analyse basique des donn√©es
        try:
            if 'execution_time' in results_df.columns:
                avg_time = results_df['execution_time'].mean()
                min_time = results_df['execution_time'].min()
                max_time = results_df['execution_time'].max()
                
                report += f"""
### Analyse basique des temps d'ex√©cution

- **Temps moyen:** {avg_time:.4f} secondes
- **Temps minimum:** {min_time:.4f} secondes
- **Temps maximum:** {max_time:.4f} secondes
- **√âcart:** {max_time - min_time:.4f} secondes

"""
            
            if 'engine' in results_df.columns:
                engine_counts = results_df['engine'].value_counts()
                report += "**R√©partition par moteur:**\n"
                for engine, count in engine_counts.items():
                    report += f"- {engine}: {count} ex√©cutions\n"
                
        except Exception as e:
            report += f"Erreur lors de l'analyse basique: {str(e)}\n"
        
        # Ajout des recommandations g√©n√©rales si demand√©
        if include_recommendations:
            report += """
## Recommandations g√©n√©rales

1. **Validation des donn√©es:** Assurez-vous que tous les tests se sont d√©roul√©s correctement
2. **Analyse plus pouss√©e:** Consultez les donn√©es brutes pour une analyse d√©taill√©e
3. **Tests suppl√©mentaires:** Consid√©rez l'ex√©cution de tests avec plus d'it√©rations
4. **Documentation:** Conservez ce rapport pour r√©f√©rence future

"""
        
        # Pied de page
        report += f"""
---

**Rapport g√©n√©r√© par la Plateforme d'√©valuation SPARQL**  
*D√©velopp√© dans le cadre d'un m√©moire de Master 2 en Informatique - G√©nie Logiciel*

*G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return report
        
    except Exception as e:
        # Rapport d'erreur minimal en cas d'√©chec complet
        return f"""# Erreur lors de la g√©n√©ration du rapport

**Type de rapport demand√©:** {report_type}
**Erreur rencontr√©e:** {str(e)}

**Informations disponibles:**
- Nombre d'enregistrements: {len(results_df) if results_df is not None else 0}
- Colonnes: {', '.join(results_df.columns) if results_df is not None and not results_df.empty else 'Aucune'}

**Suggestion:** V√©rifiez que les tests ont √©t√© ex√©cut√©s et que les donn√©es sont valides.

---
*Rapport d'erreur g√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

def render_visualization_export_section(results_df: pd.DataFrame):
    """
    Affiche la section d'export des visualisations
    
    Args:
        results_df: DataFrame des r√©sultats
    """
    st.subheader("üìä Exportation des visualisations")
    
    st.info("""
    üí° **Note:** Les graphiques interactifs Plotly peuvent √™tre sauvegard√©s directement depuis l'onglet 'Visualisation' 
    en utilisant les options d'export int√©gr√©es (ic√¥ne de l'appareil photo dans chaque graphique).
    """)
    
    # Guide pour l'export des visualisations
    with st.expander("üìñ Guide d'exportation des graphiques"):
        st.markdown("""
        ### Comment exporter les graphiques
        
        1. **Depuis l'onglet Visualisation:**
           - Allez dans l'onglet 'Visualisation'
           - Survolez un graphique avec votre souris
           - Cliquez sur l'ic√¥ne de l'appareil photo (üì∑) en haut √† droite
           - Choisissez le format (PNG, SVG, PDF)
        
        2. **Formats disponibles:**
           - **PNG:** Image haute qualit√© pour les pr√©sentations
           - **SVG:** Format vectoriel pour l'√©dition
           - **PDF:** Pour l'inclusion dans des documents
        
        3. **Qualit√© recommand√©e:**
           - R√©solution: 1200x800 pour les pr√©sentations
           - Format SVG pour les publications acad√©miques
        """)
    
    # G√©n√©ration d'un package complet
    if st.button("üì¶ G√©n√©rer un package d'export complet"):
        with st.spinner("Pr√©paration du package d'export..."):
            package_info = create_export_package_info(results_df)
            
            st.success("‚úÖ Package d'export pr√©par√©!")
            st.json(package_info)

def create_export_package_info(results_df: pd.DataFrame) -> dict:
    """
    Cr√©e les informations du package d'export
    
    Args:
        results_df: DataFrame des r√©sultats
        
    Returns:
        Dictionnaire d'informations du package
    """
    return {
        "package_info": {
            "creation_date": datetime.now().isoformat(),
            "total_records": len(results_df),
            "data_columns": list(results_df.columns),
            "export_formats": ["CSV", "Excel", "JSON", "Markdown Report"]
        },
        "contents": {
            "raw_data": "Donn√©es compl√®tes de performance",
            "summary_tables": "Tableaux r√©capitulatifs et statistiques",
            "detailed_report": "Rapport d'analyse d√©taill√©",
            "visualization_guide": "Guide pour exporter les graphiques"
        },
        "recommendations": {
            "academic_use": "Utilisez les formats Excel + SVG pour les publications",
            "business_use": "Privil√©giez CSV + PNG pour les pr√©sentations",
            "technical_use": "JSON + Markdown pour l'int√©gration technique"
        }
    }