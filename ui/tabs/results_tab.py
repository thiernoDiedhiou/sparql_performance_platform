"""
Onglet d'affichage des r√©sultats de tests
"""

import streamlit as st
import pandas as pd
from utils.data_manager import get_test_results, is_test_completed
from visualization.visualizer import ResultVisualizer
from utils.helpers import format_duration, create_benchmark_summary

def render_results_tab():
    """Affiche l'onglet des r√©sultats"""
    st.header("R√©sultats des tests")
    
    if not is_test_completed():
        st.info("‚ÑπÔ∏è Aucun test n'a encore √©t√© ex√©cut√©. Allez dans l'onglet 'Configuration et tests' pour lancer les tests.")
        return
    
    results_df = get_test_results()
    
    if results_df is None or results_df.empty:
        st.warning("‚ö†Ô∏è Aucun r√©sultat disponible.")
        return
    
    # R√©sum√© ex√©cutif
    render_executive_summary(results_df)
    
    # Filtrage des r√©sultats
    filtered_df = render_results_filters(results_df)
    
    if filtered_df.empty:
        st.warning("Aucun r√©sultat disponible apr√®s filtrage.")
        return
    
    # Tableau r√©capitulatif
    render_summary_table(filtered_df)
    
    # R√©sultats d√©taill√©s
    render_detailed_results(filtered_df)
    
    # Statistiques de performance
    render_performance_statistics(filtered_df)
    
    # Performances extr√™mes
    render_extreme_performances(filtered_df)

def render_executive_summary(results_df: pd.DataFrame):
    """
    Affiche un r√©sum√© ex√©cutif des r√©sultats
    
    Args:
        results_df: DataFrame des r√©sultats
    """
    st.subheader("üìä R√©sum√© ex√©cutif")
    
    # M√©triques principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_executions = len(results_df)
        st.metric("Ex√©cutions totales", total_executions)
    
    with col2:
        if 'query_name' in results_df.columns:
            unique_queries = results_df['query_name'].nunique()
        else:
            unique_queries = 1
        st.metric("Requ√™tes test√©es", unique_queries)
    
    with col3:
        if 'engine' in results_df.columns:
            engines_tested = results_df['engine'].nunique()
        else:
            engines_tested = 1
        st.metric("Moteurs test√©s", engines_tested)
    
    with col4:
        if 'success' in results_df.columns:
            success_rate = results_df['success'].mean() * 100
        else:
            success_rate = 0
        st.metric("Taux de succ√®s", f"{success_rate:.1f}%")
    
    # Performance globale
    st.subheader("üéØ Performance globale")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'execution_time' in results_df.columns:
            avg_time = results_df['execution_time'].mean()
            st.metric("Temps moyen", format_duration(avg_time))
        
    with col2:
        if 'execution_time' in results_df.columns:
            min_time = results_df['execution_time'].min()
            st.metric("Temps minimum", format_duration(min_time))
    
    with col3:
        if 'execution_time' in results_df.columns:
            max_time = results_df['execution_time'].max()
            st.metric("Temps maximum", format_duration(max_time))
    
    # Comparaison par moteur
    if 'engine' in results_df.columns and 'execution_time' in results_df.columns:
        st.subheader("‚öñÔ∏è Comparaison par moteur")
        
        engine_comparison = results_df.groupby('engine').agg({
            'execution_time': ['mean', 'count'],
            'success': 'mean'
        }).round(4)
        
        engine_comparison.columns = ['Temps moyen (s)', 'Ex√©cutions', 'Taux de succ√®s']
        engine_comparison['Taux de succ√®s'] = (engine_comparison['Taux de succ√®s'] * 100).round(2)
        
        st.dataframe(engine_comparison, use_container_width=True)
        
        # Recommandation rapide
        best_engine = engine_comparison['Temps moyen (s)'].idxmin()
        st.success(f"üèÜ **Moteur le plus performant:** {best_engine}")

def render_results_filters(results_df: pd.DataFrame) -> pd.DataFrame:
    """
    Affiche les filtres pour les r√©sultats et retourne les donn√©es filtr√©es
    
    Args:
        results_df: DataFrame des r√©sultats
        
    Returns:
        DataFrame filtr√©
    """
    st.subheader("üîç Filtrage des r√©sultats")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Filtre par moteur
        engine_filter = []
        if 'engine' in results_df.columns:
            engines = results_df['engine'].unique()
            engine_filter = st.multiselect(
                "Moteur SPARQL",
                options=engines,
                default=engines,
                help="S√©lectionnez les moteurs √† afficher"
            )
    
    with col2:
        # Filtre par requ√™te
        query_filter = []
        if 'query_name' in results_df.columns:
            queries = results_df['query_name'].unique()
            query_filter = st.multiselect(
                "Requ√™te",
                options=queries,
                default=queries,
                help="S√©lectionnez les requ√™tes √† afficher"
            )
    
    with col3:
        # Filtre par statut de succ√®s
        success_filter = st.radio(
            "Statut",
            options=["Tous", "Succ√®s seulement", "√âchecs seulement"],
            index=0,
            help="Filtrer par statut d'ex√©cution"
        )
    
    # Application des filtres
    filtered_df = results_df.copy()
    
    if engine_filter:
        filtered_df = filtered_df[filtered_df['engine'].isin(engine_filter)]
    
    if query_filter:
        filtered_df = filtered_df[filtered_df['query_name'].isin(query_filter)]
    
    if success_filter == "Succ√®s seulement":
        filtered_df = filtered_df[filtered_df['success'] == True]
    elif success_filter == "√âchecs seulement":
        filtered_df = filtered_df[filtered_df['success'] == False]
    
    # Affichage du nombre de r√©sultats apr√®s filtrage
    st.info(f"üìà {len(filtered_df)} r√©sultats affich√©s (sur {len(results_df)} au total)")
    
    return filtered_df

def render_summary_table(filtered_df: pd.DataFrame):
    """
    Affiche le tableau r√©capitulatif des performances
    
    Args:
        filtered_df: DataFrame filtr√© des r√©sultats
    """
    st.subheader("üìã Tableau r√©capitulatif")
    
    try:
        visualizer = ResultVisualizer()
        summary_table = visualizer.create_summary_table(filtered_df)
        
        # Configuration de l'affichage du dataframe
        st.dataframe(
            summary_table,
            use_container_width=True,
            height=400
        )
        
        # Bouton de t√©l√©chargement du r√©sum√©
        csv_summary = summary_table.to_csv(index=False)
        st.download_button(
            label="üì• T√©l√©charger le r√©sum√© (CSV)",
            data=csv_summary,
            file_name="resume_performance_sparql.csv",
            mime="text/csv"
        )
        
    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation du tableau r√©capitulatif: {str(e)}")

def render_detailed_results(filtered_df: pd.DataFrame):
    """
    Affiche les r√©sultats d√©taill√©s
    
    Args:
        filtered_df: DataFrame filtr√© des r√©sultats
    """
    st.subheader("üìÑ R√©sultats d√©taill√©s")
    
    # Options d'affichage
    col1, col2 = st.columns(2)
    
    with col1:
        show_all_columns = st.checkbox("Afficher toutes les colonnes", value=False)
    
    with col2:
        max_rows = st.selectbox(
            "Nombre de lignes √† afficher",
            options=[50, 100, 200, 500, "Toutes"],
            index=0
        )
    
    # Pr√©paration des donn√©es
    display_df = filtered_df.copy()
    
    if not show_all_columns:
        # Colonnes essentielles
        essential_columns = ['query_name', 'engine', 'iteration', 'execution_time', 'success', 'result_count']
        available_columns = [col for col in essential_columns if col in display_df.columns]
        display_df = display_df[available_columns]
    
    # Formatage des colonnes num√©riques
    if 'execution_time' in display_df.columns:
        display_df['execution_time'] = display_df['execution_time'].round(4)
    if 'cpu_usage' in display_df.columns:
        display_df['cpu_usage'] = display_df['cpu_usage'].round(2)
    if 'memory_usage' in display_df.columns:
        display_df['memory_usage'] = display_df['memory_usage'].round(2)
    
    # Limitation du nombre de lignes
    if max_rows != "Toutes":
        display_df = display_df.head(max_rows)
    
    # Affichage
    st.dataframe(
        display_df,
        use_container_width=True,
        height=500
    )
    
    # Bouton de t√©l√©chargement des r√©sultats d√©taill√©s
    csv_detailed = filtered_df.to_csv(index=False)
    st.download_button(
        label="üì• T√©l√©charger les r√©sultats d√©taill√©s (CSV)",
        data=csv_detailed,
        file_name="resultats_detailles_sparql.csv",
        mime="text/csv"
    )

def render_performance_statistics(filtered_df: pd.DataFrame):
    """
    Affiche les statistiques de performance
    
    Args:
        filtered_df: DataFrame filtr√© des r√©sultats
    """
    st.subheader("üìä Statistiques de performance")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**‚è±Ô∏è Temps d'ex√©cution (secondes)**")
        if 'execution_time' in filtered_df.columns:
            execution_stats = filtered_df.groupby(['query_name', 'engine'])['execution_time'].describe()
            st.dataframe(execution_stats.round(4), use_container_width=True)
        else:
            st.info("Donn√©es de temps d'ex√©cution non disponibles")
    
    with col2:
        st.write("**üíª Utilisation des ressources**")
        if all(col in filtered_df.columns for col in ['cpu_usage', 'memory_usage']):
            resource_stats = filtered_df.groupby(['query_name', 'engine']).agg({
                'cpu_usage': ['mean', 'max'],
                'memory_usage': ['mean', 'max']
            }).round(2)
            
            resource_stats.columns = ['CPU moy.', 'CPU max', 'M√©m. moy.', 'M√©m. max']
            st.dataframe(resource_stats, use_container_width=True)
        else:
            st.info("Donn√©es de ressources non disponibles")

def render_extreme_performances(filtered_df: pd.DataFrame):
    """
    Affiche les performances extr√™mes (meilleures et pires)
    
    Args:
        filtered_df: DataFrame filtr√© des r√©sultats
    """
    st.subheader("üèÅ Performances extr√™mes")
    
    if 'execution_time' not in filtered_df.columns:
        st.info("Donn√©es de temps d'ex√©cution non disponibles")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üöÄ Top 5 des ex√©cutions les plus rapides**")
        fastest = filtered_df.nsmallest(5, 'execution_time')[
            ['engine', 'query_name', 'execution_time', 'iteration']
        ].copy()
        
        if not fastest.empty:
            fastest['execution_time'] = fastest['execution_time'].apply(format_duration)
            fastest.columns = ['Moteur', 'Requ√™te', 'Temps', 'It√©ration']
            st.dataframe(fastest, use_container_width=True, hide_index=True)
        else:
            st.info("Aucune donn√©e disponible")
    
    with col2:
        st.write("**üêå Top 5 des ex√©cutions les plus lentes**")
        slowest = filtered_df.nlargest(5, 'execution_time')[
            ['engine', 'query_name', 'execution_time', 'iteration']
        ].copy()
        
        if not slowest.empty:
            slowest['execution_time'] = slowest['execution_time'].apply(format_duration)
            slowest.columns = ['Moteur', 'Requ√™te', 'Temps', 'It√©ration']
            st.dataframe(slowest, use_container_width=True, hide_index=True)
        else:
            st.info("Aucune donn√©e disponible")
    
    # Analyse des √©carts de performance
    if 'query_name' in filtered_df.columns and 'engine' in filtered_df.columns:
        st.subheader("üìà Analyse des √©carts de performance")
        
        # Calcul des ratios de performance entre moteurs
        try:
            performance_analysis = analyze_performance_gaps(filtered_df)
            
            if performance_analysis:
                st.write("**Comparaison Virtuoso vs Jena Fuseki:**")
                
                for analysis in performance_analysis:
                    if analysis['ratio'] < 0.95:
                        emoji = "üü¢"
                        status = "Virtuoso plus rapide"
                    elif analysis['ratio'] > 1.05:
                        emoji = "üî¥"
                        status = "Fuseki plus rapide"
                    else:
                        emoji = "üü°"
                        status = "Performances similaires"
                    
                    st.write(f"{emoji} **{analysis['query']}**: {status} (ratio: {analysis['ratio']:.2f})")
            
        except Exception as e:
            st.error(f"Erreur lors de l'analyse des √©carts: {str(e)}")

def analyze_performance_gaps(df: pd.DataFrame) -> list:
    """
    Analyse les √©carts de performance entre moteurs
    
    Args:
        df: DataFrame des r√©sultats
        
    Returns:
        Liste des analyses par requ√™te
    """
    try:
        # Grouper par requ√™te et moteur
        grouped = df.groupby(['query_name', 'engine'])['execution_time'].mean().reset_index()
        
        analysis_results = []
        
        # Pour chaque requ√™te, comparer Virtuoso et Fuseki
        for query in grouped['query_name'].unique():
            query_data = grouped[grouped['query_name'] == query]
            
            virtuoso_data = query_data[query_data['engine'].str.contains('Virtuoso', case=False)]
            fuseki_data = query_data[query_data['engine'].str.contains('Fuseki', case=False)]
            
            if not virtuoso_data.empty and not fuseki_data.empty:
                virtuoso_time = virtuoso_data['execution_time'].iloc[0]
                fuseki_time = fuseki_data['execution_time'].iloc[0]
                
                ratio = virtuoso_time / fuseki_time if fuseki_time > 0 else float('inf')
                
                analysis_results.append({
                    'query': query,
                    'virtuoso_time': virtuoso_time,
                    'fuseki_time': fuseki_time,
                    'ratio': ratio
                })
        
        return analysis_results
        
    except Exception as e:
        return []